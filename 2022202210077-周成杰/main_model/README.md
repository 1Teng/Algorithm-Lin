# 在线3D装箱问题：基于空间状态树表示的强化学习方案

## 问题建模

在线3D装箱问题属于一种组合最优化问题，其目的是在给定的约束条件下优化装箱的位置，它与离线3D装箱问题（一个NP-hard问题）的主要区别是没有对待装箱的序列的先验知识，必须根据物品到来的顺序对其进行放置。此问题最早由Steven等人在2002年提出。

首先讨论此问题的约束条件，在本次实验中约束条件比较简单，没有基于实际物理性质所归纳的条件约束（比如基于密度的承重约束、基于重心的稳定性约束等），假定所有物体（item）集合为I，总空间为S，每一个物体i的与（0,0,0）对应的角的坐标为 $ p_{i}^{d},{i}\in {I},{d}\in{{x},{y},{z}} $，占用的空间为 $s_{i}^{d},{i}\in{I},{d}\in{{x},{y},{z}}$，约束条件总结如下：

- 不重叠约束：$p_i^d+s_i^d\le p_j^d，i≠j,i,j∈I,d∈{x,y,z}$
- 边界约束：$0\le p_i^d\le S^d-s_i^d，i∈I,d∈{x,y,z}$

现在基于高级算法课程所教授的**状态空间搜索求解**的模式来对在线3D装箱问题的解空间进行建模。首先是状态的描述，可以分为历史信息描述（已装箱的物体和占用空间）、当前物体、未装箱空间三个部分。发现对于n-D空间的在线装箱，存在n叉树对当前的装箱状态进行描述。下面将从简化的问题（2D装箱）到实际问题（3D装箱）对这种状态树形建模方法进行说明。
![img1](/assets/img1.png)
首先是2D在线装箱的初始状态，上图的左子图代表目前未装箱的空间（S），第一个物品（0）到来，唯一候选的装箱节点为根节点（即蓝圈所示坐标（0,0）节点），形成仅有根节点的状态树。
![img2](/assets/img2.png)
下一步，第二个物品（1）到来，当前未装箱的空间可以由第一个物品分成上和右两个区域，分别对应两个候选的装箱节点（左子节点对应1放在0上，右子节点对应1放在0右，蓝圈所示为1的左下角对应坐标），假定此时选择将1放在0上，将1作为0的左子节点更新状态树。
![img3](/assets/img3.png)
第三个物品（2）到来，当前未装箱空间可以由第一第二个物品分成（0-右，1-上，1-右）三个区域，分别对应3个候选的装箱节点（1的左子节点对应2放在1上，1的右子节点对应2放在1右，0的右子节点对应2放在0右，此时0的左子节点为1，代表2不能放在0上，蓝圈所示为2的左下角对应坐标），，假定此时选择将2放在0右，将2作为0的右子节点更新状态树。
![img4](/assets/img4.png)
第四个物品（3）到来，当前未装箱空间可以由第1-3个物品分成（1-上，1-右，2-上）三个区域（2-右区域模拟恰好与边界重合，不能装箱的情况），分别对应3个候选的装箱节点（1的左子节点对应3放在1上，1的右子节点对应3放在1右，2的左子节点对应3放在2上，此时0的左子节点为1，右子节点为2，蓝圈所示为3的左下角对应坐标），假定此时选择将3放在2上，将3作为2的左子节点更新状态树。

**具体说明和3D装箱状态示意图参看作业文档。** 这一步的结论是在3D装箱过程中可以使用确定结构的树（3叉树）来对当前的装箱状态（包含已装箱的物体和位置以及下一步的候选装箱位置（即分区域的未装箱空间）进行描述，这种结构化的描述能够高效地描述问题空间和解空间的状态。

## 理论方案设计

本节对搜索方法进行研究。在这一部中我充分调研了现有方案，从我本人的专业——自然语言处理中的结构化句法语义分析——出发，结合上一步产生的问题建模，选择并实现了基于空间状态树表示的强化学习方案，这是一种基于人工神经网络模型和强化学习方法的实现方案。接下来我将介绍如何从空间状态树表示经由训练产生决策函数（policy）以及我的具体实现。

*状态树的表示*：显然结构化的树结构数据没办法直接用于神经网络的计算。在自然语言处理的依存分析中，句子的依存语法树可以使用递归神经网络、TreeLSTM、图神经网络等方法进行特征表示。针对状态树子节点数固定的特点，采用GAT（Graph Attention Network，一种图神经网络结构）【2】进行状态树的特征提取，其中的Attention计算方式采用Transformer【3】结构中的Scaled Dot-Product Attention，即比例点积自注意力。首先将t时刻的状态树划分为叶子节点 ${L}_{t}$ 和非叶子节点 $ {B}_{t}$，它们分别代表了候选节点的位置信息和已装箱节点的位置信息，t时刻到来的物品i的形状和方位信息用 ${n}_{t}$表示，那么t时刻的初始状态信息可以表示为:
$$\hat{\mathbf{h}}=\left\{\phi_{\theta_B}\left(\mathbf{B}_t\right),\phi_{\theta_L}\left(\mathbf{L}_t\right),\phi_{\theta_n}\left(n_t\right)\right\}$$
$$\phi_{\theta_x}=MLP(x)=Wx+b$$
用3个独立的MLP进行非线性变换再通过线性组合得到初始的状态表示，GAT的计算过程如下:
$$GAT\left({\hat{h}}_i\right)=W^O\sum_{j=1}^{N} softmax\left(\frac{\left(W^Q{\hat{h}}_i\right)^TW^K{\hat{h}}_j}{\sqrt{d_k}}\right)W^V{\hat{h}}_j$$
其中W是可学习的参数，仿照Transformer Encoder的设计，采用Skip-connection的方式，最终的状态空间树表示为初始状态表示与GAT提取的状态表示之和。
$$\mathbf{h}^\prime=\hat{\mathbf{h}}+GAT(\hat{\mathbf{h}})$$

*候选节点的选取（决策函数）*：根据t时刻的状态需要从候选的节点（即叶子节点 ${L}_{t}）$中挑选最优。在自然语言处理的依存句法分析中，经常使用Pointer Network进行序列到序列（seq2seq）的处理。这里同样使用了这个方法，对 ${h}_{i}\in{L}_{t},{i}\in\mathbf{1},{N}$ ,首先计算每个候选节点表示对序列平均表示的自注意力表示：
$$q=W^q\bar{h}，ki=W^{k}h_i，vi=\frac{q^{T}k_{i}}{\sqrt[k]{d}}$$
决策函数是整个序列自注意力表示的Softmax输出（概率最大的解）：
$$\pi_\theta\left(\mathbf{L}_t\mid B_t,\mathbf{L}_t,n_t\right)=softmax\left(c\cdot\tanh\left(v_\mathbf{L}\right)\right)$$

*强化学习过程*：现有研究表明，在线3D装箱的决策过程是一个马尔可夫决策过程，即每一步所作出的决策取决于当前时刻的状态。在强化学习过程的训练中我借鉴了Zhao等人【5】设计的结构，他们在2021 AAAI上针对3D装箱问题设计了强化学习的解决方案，采用了马尔可夫决策过程和ACKTR训练策略。与本方案不同的是他们建模方法是基于箱体3视图的CNN特征提取方法，采用方格标注的方法进行建模。训练采用随机生成的数据。具体可以参看实验文档。

## 代码结构和运行说明

代码包含强化学习方案实现和用于比较性能的启发式算法实现。

在RL文件夹下是强化学习的部分，wrapper和pct_envs文件夹包含了gym强化学习环境的定义，model.py、attention_model.py、graph_encoder.py文件实现了状态树的向量表示、基于GAT和自注意力强化学习模型，kfac.py文件是强化学习ACKTR梯度下降方法的实现，训练过程在main.py中，测试过程在evaluation.py中，几个tool.py文件是辅助测试和训练的方法。

Heuristic文件夹下是启发式算法的部分，bin.py文件定义了容器的参数和考察的约束条件，item.py定义了箱子和不同旋转的箱子的参数，method.py定义了启发式方法，packer.py定义了装箱过程和输出装箱结果的部分。基于最大剩余空间的启发式方法可以参考实验文档。

使用随机生成的数据训练和测试强化学习模型代码如下，命令行选项定义了状态树的一些超参数，包括最大状态树的叶子节点数和内部节点数：

```python
python main.py  --internal-node-holder 80 --leaf-node-holder 50
python evaluation.py --evaluate --load-model --model-path  --load-dataset --dataset-path 

```

由于Github对上传文件大小的限制([Github Document](https://docs.github.com/zh/repositories/working-with-files/managing-large-files/about-large-files-on-github))，强化学习模型和数据无法上传，同时由于对GPU资源、CUDA环境和依赖库版本的需要，测试数据也需要保存成Torch.tensor格式，没有办法进行简单的测试。**这方面具体的实现和运行情况可以参看实验文档**。老师可以测试启发式算法实现，在文档中同样有所说明，同样可以达到较高的效率。

启发式算法的运行较为简单，不需要GPU计算资源和强化学习环境。运行方式为

```python
python example.py 

```

在example.py中可以修改测试的箱子和容器的数据。测试结果可以参考实验文档。
